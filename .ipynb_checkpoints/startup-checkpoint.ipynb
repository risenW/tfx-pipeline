{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 44.9M  100 44.9M    0     0   111M      0 --:--:-- --:--:-- --:--:--  111M\n"
     ]
    }
   ],
   "source": [
    "# Install tfx and kfp Python packages.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "!{sys.executable} -m pip install --user --upgrade -q tfx\n",
    "!{sys.executable} -m pip install --user --upgrade -q kfp\n",
    "# Download skaffold and set it executable.\n",
    "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold && mv skaffold /home/jupyter/.local/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.23.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_CLOUD_PROJECT=tfx-project-288611\n",
      "GCP project ID:tfx-project-288611\n"
     ]
    }
   ],
   "source": [
    "# Read GCP project id from env.\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
    "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
    "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This refers to the KFP cluster endpoint\n",
    "ENDPOINT='https://39aee44fc104321f-dot-us-central2.pipelines.googleusercontent.com'\n",
    "if not ENDPOINT:\n",
    "    from absl import logging\n",
    "    logging.error('Set your ENDPOINT in this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker image name for the pipeline image.\n",
    "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/house_price_pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_NAME=\"taxi_template\"\n",
    "PIPELINE_NAME=\"house_price_pipeline\"\n",
    "\n",
    "TEMPLATE_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",TEMPLATE_NAME)\n",
    "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tfx template copy \\\n",
    "#   --pipeline-name={TEMPLATE_NAME} \\\n",
    "#   --destination-path={TEMPLATE_DIR} \\\n",
    "#   --model=taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {\"~/imported/house_price_pipeline\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dataset to GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][514.4 KiB/514.4 KiB]                                                \n",
      "Operation completed over 1 objects/514.4 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-hprice/data/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 14:34:01.697683: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-09-06 14:34:01.697814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "CLI\n",
      "Creating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Reading build spec from build.yaml\n",
      "Target image gcr.io/tfx-project-288611/house_price_pipeline is not used. If the build spec is provided, update the target image in the build spec file build.yaml.\n",
      "[Skaffold] Generating tags...\n",
      "[Skaffold]  - gcr.io/tfx-project-288611/hprice-pipeline -> gcr.io/tfx-project-288611/hprice-pipeline:latest\n",
      "[Skaffold] Checking cache...\n",
      "[Skaffold]  - gcr.io/tfx-project-288611/hprice-pipeline: Not found. Building\n",
      "[Skaffold] Building [gcr.io/tfx-project-288611/hprice-pipeline]...\n",
      "Sending build context to Docker daemon  594.4kBon  530.9kB\n",
      "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
      "[Skaffold]  ---> f8355268ae44\n",
      "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
      "[Skaffold]  ---> Using cache\n",
      "[Skaffold]  ---> a0b803347102\n",
      "[Skaffold] Step 3/4 : COPY ./ ./\n",
      "[Skaffold]  ---> 3ad0b57c47f5\n",
      "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      "[Skaffold]  ---> Running in 23c5e18b32b1\n",
      "[Skaffold]  ---> 0d5f2294cd02\n",
      "[Skaffold] Successfully built 0d5f2294cd02\n",
      "[Skaffold] Successfully tagged gcr.io/tfx-project-288611/hprice-pipeline:latest\n",
      "[Skaffold] The push refers to repository [gcr.io/tfx-project-288611/hprice-pipeline]\n",
      "[Skaffold] aac31e92161c: Preparing\n",
      "[Skaffold] d4d9b8495dd8: Preparing\n",
      "[Skaffold] 9042e84a180f: Preparing\n",
      "[Skaffold] 4f874315440c: Preparing\n",
      "[Skaffold] f13a156e38fd: Preparing\n",
      "[Skaffold] 572b4b19939e: Preparing\n",
      "[Skaffold] d8bc156b2e76: Preparing\n",
      "[Skaffold] 4058ae03fa32: Preparing\n",
      "[Skaffold] e3437c61d457: Preparing\n",
      "[Skaffold] 84ff92691f90: Preparing\n",
      "[Skaffold] 54b00d861a7a: Preparing\n",
      "[Skaffold] c547358928ab: Preparing\n",
      "[Skaffold] 84ff92691f90: Preparing\n",
      "[Skaffold] c4e66be694ce: Preparing\n",
      "[Skaffold] 47cc65c6dd57: Preparing\n",
      "[Skaffold] 572b4b19939e: Waiting\n",
      "[Skaffold] d8bc156b2e76: Waiting\n",
      "[Skaffold] 4058ae03fa32: Waiting\n",
      "[Skaffold] e3437c61d457: Waiting\n",
      "[Skaffold] 84ff92691f90: Waiting\n",
      "[Skaffold] 54b00d861a7a: Waiting\n",
      "[Skaffold] c547358928ab: Waiting\n",
      "[Skaffold] c4e66be694ce: Waiting\n",
      "[Skaffold] 47cc65c6dd57: Waiting\n",
      "[Skaffold] 9042e84a180f: Layer already exists\n",
      "[Skaffold] 4f874315440c: Layer already exists\n",
      "[Skaffold] f13a156e38fd: Layer already exists\n",
      "[Skaffold] d4d9b8495dd8: Layer already exists\n",
      "[Skaffold] 572b4b19939e: Layer already exists\n",
      "[Skaffold] 4058ae03fa32: Layer already exists\n",
      "[Skaffold] d8bc156b2e76: Layer already exists\n",
      "[Skaffold] e3437c61d457: Layer already exists\n",
      "[Skaffold] 54b00d861a7a: Layer already exists\n",
      "[Skaffold] 84ff92691f90: Layer already exists\n",
      "[Skaffold] c4e66be694ce: Layer already exists\n",
      "[Skaffold] c547358928ab: Layer already exists\n",
      "[Skaffold] 47cc65c6dd57: Layer already exists\n",
      "[Skaffold] aac31e92161c: Pushed\n",
      "[Skaffold] latest: digest: sha256:1434db83896789c711f8713678db9534144681179f21cab452dbecfc7c4c6f8c size: 3478\n",
      "New container image is built. Target image is available in the build spec file.\n",
      "2020-09-06 14:34:16.199070: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-09-06 14:34:16.199187: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
      "WARNING:tensorflow:From /home/jupyter/imported/house_price_pipeline/pipeline/pipeline.py:52: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "external_input is deprecated, directly pass the uri to ExampleGen.\n",
      "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
      "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
      "INFO:absl:Adding upstream dependencies for component ResolverNode_latest_blessed_model_resolver\n",
      "INFO:absl:Adding upstream dependencies for component StatisticsGen\n",
      "INFO:absl:   ->  Component: CsvExampleGen\n",
      "INFO:absl:Adding upstream dependencies for component SchemaGen\n",
      "INFO:absl:   ->  Component: StatisticsGen\n",
      "INFO:absl:Adding upstream dependencies for component ExampleValidator\n",
      "INFO:absl:   ->  Component: SchemaGen\n",
      "INFO:absl:   ->  Component: StatisticsGen\n",
      "INFO:absl:Adding upstream dependencies for component Transform\n",
      "INFO:absl:   ->  Component: CsvExampleGen\n",
      "INFO:absl:   ->  Component: SchemaGen\n",
      "INFO:absl:Adding upstream dependencies for component Trainer\n",
      "INFO:absl:   ->  Component: SchemaGen\n",
      "INFO:absl:   ->  Component: Transform\n",
      "INFO:absl:Adding upstream dependencies for component Evaluator\n",
      "INFO:absl:   ->  Component: CsvExampleGen\n",
      "INFO:absl:   ->  Component: ResolverNode_latest_blessed_model_resolver\n",
      "INFO:absl:   ->  Component: Trainer\n",
      "INFO:absl:Adding upstream dependencies for component Pusher\n",
      "INFO:absl:   ->  Component: Evaluator\n",
      "INFO:absl:   ->  Component: Trainer\n",
      "\u001b[0mPipeline compiled successfully.\n",
      "Pipeline package path: /home/jupyter/imported/house_price_pipeline/house_price_pipeline.tar.gz\n",
      "Pipeline \"house_price_pipeline\" already exists.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline-path=kubeflow_dag_runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build-target-image={CUSTOM_TFX_IMAGE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 14:21:49.355917: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-09-06 14:21:49.356054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "CLI\n",
      "Creating a run for pipeline: house_price_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Run created for pipeline: house_price_pipeline\n",
      "+----------------------+--------------------------------------+----------+---------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "| pipeline_name        | run_id                               | status   | created_at                | link                                                                                                                         |\n",
      "+======================+======================================+==========+===========================+==============================================================================================================================+\n",
      "| house_price_pipeline | c63f1f05-1fc7-4145-b8cd-d4247f53fd70 |          | 2020-09-06T14:21:54+00:00 | https://39aee44fc104321f-dot-us-central2.pipelines.googleusercontent.com/#/runs/details/c63f1f05-1fc7-4145-b8cd-d4247f53fd70 |\n",
      "+----------------------+--------------------------------------+----------+---------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!tfx run create --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 16:09:32.768132: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-09-06 16:09:32.768278: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "CLI\n",
      "Updating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "New container image is built. Target image is available in the build spec file.\n",
      "Invalid pipeline path: kubeflow_dag_runner.py\n",
      "\u001b[0m2020-09-06 16:09:39.056856: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-09-06 16:09:39.057010: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "CLI\n",
      "Creating a run for pipeline: house_price_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Run created for pipeline: house_price_pipeline\n",
      "+----------------------+--------------------------------------+----------+---------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "| pipeline_name        | run_id                               | status   | created_at                | link                                                                                                                         |\n",
      "+======================+======================================+==========+===========================+==============================================================================================================================+\n",
      "| house_price_pipeline | b671d82a-5bef-4ef6-baba-97dafddd5ee2 |          | 2020-09-06T16:09:44+00:00 | https://39aee44fc104321f-dot-us-central2.pipelines.googleusercontent.com/#/runs/details/b671d82a-5bef-4ef6-baba-97dafddd5ee2 |\n",
      "+----------------------+--------------------------------------+----------+---------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Update the pipeline\n",
    "!tfx pipeline update \\\n",
    "--pipeline-path=kubeflow_dag_runner.py \\\n",
    "--endpoint={ENDPOINT}\n",
    "# You can run the pipeline the same way.\n",
    "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
